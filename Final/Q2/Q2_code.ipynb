{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AMGCVTFdYp6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5602d1c4-7cb0-4ba8-bae7-2538be95f6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class WeatherDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.image_files = os.listdir(data_dir)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
        "            transforms.ToTensor(),  # Convert to tensor\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_files[idx]\n",
        "        image_path = os.path.join(self.data_dir, image_name)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = self.transform(image)\n",
        "        # Extract label information\n",
        "        label_name = image_name.split('.')[0]  # Remove file extension\n",
        "        label = self.get_label(label_name)\n",
        "\n",
        "        return image_tensor, label\n",
        "\n",
        "    def get_label(self, label_name):\n",
        "        # Return one-hot encoded label based on label name\n",
        "        if label_name.startswith('Cloudy'):\n",
        "            return torch.tensor([1, 0, 0, 0, 0])\n",
        "        elif label_name.startswith('Foggy'):\n",
        "            return torch.tensor([0, 1, 0, 0, 0])\n",
        "        elif label_name.startswith('Rainy'):\n",
        "            return torch.tensor([0, 0, 1, 0, 0])\n",
        "        elif label_name.startswith('Snowy'):\n",
        "            return torch.tensor([0, 0, 0, 1, 0])\n",
        "        elif label_name.startswith('Sunny'):\n",
        "            return torch.tensor([0, 0, 0, 0, 1])\n",
        "        else:\n",
        "            raise ValueError('Invalid label name')\n",
        "\n",
        "# Set training data directory\n",
        "train_data_dir = '/content/drive/MyDrive/Colab Notebooks/5002/data/Data_Q2/train_data'\n",
        "\n",
        "# Create dataset\n",
        "dataset = WeatherDataset(train_data_dir)\n",
        "\n",
        "# Set batch size and shuffle\n",
        "batch_size = 32\n",
        "shuffle = True\n",
        "\n",
        "# Create data loader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "ebRQF6uiZ2Yj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the convolutional neural network model\n",
        "class WeatherClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(WeatherClassifier, self).__init__()\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        num_features = self.base_model.fc.in_features\n",
        "        self.base_model.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        return x\n",
        "\n",
        "# Set training parameters\n",
        "num_epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = WeatherClassifier(num_classes=5)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Make sure the model is in training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print loss and accuracy for each epoch\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = correct / total * 100\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\\t Loss: {epoch_loss:.4f}\\t Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the entire training dataset\n",
        "model.eval()  # Make sure the model is in evaluation mode\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "# Calculate accuracy on the training set\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\nAccuracy on training set: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XA8Mc9Sh1k3",
        "outputId": "91fd6754-b8f2-46e4-95ef-156741a7fc27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50]\t Loss: 0.8685\t Accuracy: 67.20%\n",
            "Epoch [2/50]\t Loss: 0.5025\t Accuracy: 84.40%\n",
            "Epoch [3/50]\t Loss: 0.2452\t Accuracy: 89.20%\n",
            "Epoch [4/50]\t Loss: 0.1419\t Accuracy: 94.40%\n",
            "Epoch [5/50]\t Loss: 0.1959\t Accuracy: 95.20%\n",
            "Epoch [6/50]\t Loss: 0.2013\t Accuracy: 92.40%\n",
            "Epoch [7/50]\t Loss: 0.1565\t Accuracy: 94.80%\n",
            "Epoch [8/50]\t Loss: 0.0788\t Accuracy: 96.80%\n",
            "Epoch [9/50]\t Loss: 0.1003\t Accuracy: 96.80%\n",
            "Epoch [10/50]\t Loss: 0.1160\t Accuracy: 96.80%\n",
            "Epoch [11/50]\t Loss: 0.1152\t Accuracy: 96.00%\n",
            "Epoch [12/50]\t Loss: 0.1153\t Accuracy: 95.60%\n",
            "Epoch [13/50]\t Loss: 0.0863\t Accuracy: 97.20%\n",
            "Epoch [14/50]\t Loss: 0.0522\t Accuracy: 98.00%\n",
            "Epoch [15/50]\t Loss: 0.0443\t Accuracy: 97.60%\n",
            "Epoch [16/50]\t Loss: 0.0192\t Accuracy: 99.20%\n",
            "Epoch [17/50]\t Loss: 0.1000\t Accuracy: 96.80%\n",
            "Epoch [18/50]\t Loss: 0.0552\t Accuracy: 97.60%\n",
            "Epoch [19/50]\t Loss: 0.0469\t Accuracy: 98.40%\n",
            "Epoch [20/50]\t Loss: 0.0730\t Accuracy: 97.60%\n",
            "Epoch [21/50]\t Loss: 0.0684\t Accuracy: 98.00%\n",
            "Epoch [22/50]\t Loss: 0.0536\t Accuracy: 97.60%\n",
            "Epoch [23/50]\t Loss: 0.0682\t Accuracy: 97.20%\n",
            "Epoch [24/50]\t Loss: 0.0663\t Accuracy: 97.20%\n",
            "Epoch [25/50]\t Loss: 0.0616\t Accuracy: 98.00%\n",
            "Epoch [26/50]\t Loss: 0.0218\t Accuracy: 99.20%\n",
            "Epoch [27/50]\t Loss: 0.0315\t Accuracy: 98.40%\n",
            "Epoch [28/50]\t Loss: 0.0215\t Accuracy: 99.20%\n",
            "Epoch [29/50]\t Loss: 0.0124\t Accuracy: 99.60%\n",
            "Epoch [30/50]\t Loss: 0.0127\t Accuracy: 99.60%\n",
            "Epoch [31/50]\t Loss: 0.0086\t Accuracy: 99.60%\n",
            "Epoch [32/50]\t Loss: 0.0082\t Accuracy: 99.60%\n",
            "Epoch [33/50]\t Loss: 0.0094\t Accuracy: 99.60%\n",
            "Epoch [34/50]\t Loss: 0.0074\t Accuracy: 99.60%\n",
            "Epoch [35/50]\t Loss: 0.0076\t Accuracy: 99.60%\n",
            "Epoch [36/50]\t Loss: 0.0068\t Accuracy: 99.60%\n",
            "Epoch [37/50]\t Loss: 0.0068\t Accuracy: 99.20%\n",
            "Epoch [38/50]\t Loss: 0.0063\t Accuracy: 100.00%\n",
            "Epoch [39/50]\t Loss: 0.0062\t Accuracy: 99.60%\n",
            "Epoch [40/50]\t Loss: 0.0056\t Accuracy: 100.00%\n",
            "Epoch [41/50]\t Loss: 0.0083\t Accuracy: 99.20%\n",
            "Epoch [42/50]\t Loss: 0.0058\t Accuracy: 99.60%\n",
            "Epoch [43/50]\t Loss: 0.0072\t Accuracy: 99.60%\n",
            "Epoch [44/50]\t Loss: 0.0051\t Accuracy: 99.60%\n",
            "Epoch [45/50]\t Loss: 0.0073\t Accuracy: 99.60%\n",
            "Epoch [46/50]\t Loss: 0.0087\t Accuracy: 99.60%\n",
            "Epoch [47/50]\t Loss: 0.0070\t Accuracy: 99.20%\n",
            "Epoch [48/50]\t Loss: 0.0093\t Accuracy: 99.60%\n",
            "Epoch [49/50]\t Loss: 0.0047\t Accuracy: 100.00%\n",
            "Epoch [50/50]\t Loss: 0.0052\t Accuracy: 99.60%\n",
            "\n",
            "Accuracy on training set: 99.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = WeatherClassifier(num_classes=5)\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "        print(f\"{name}: {module}\")\n",
        "        #print(f\"Input Shape: {list(module.weight.shape)}\")\n",
        "        if module.bias is not None:\n",
        "            print(f\"Output Shape: {list(module.bias.shape)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCqU7-45d_1O",
        "outputId": "28ddfcc4-bdeb-4177-d1df-22d006be3745"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.conv1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "base_model.layer1.0.conv1: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer1.0.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer1.1.conv1: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer1.1.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer2.0.conv1: Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "base_model.layer2.0.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer2.0.downsample.0: Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "base_model.layer2.1.conv1: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer2.1.conv2: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer3.0.conv1: Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "base_model.layer3.0.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer3.0.downsample.0: Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "base_model.layer3.1.conv1: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer3.1.conv2: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer4.0.conv1: Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "base_model.layer4.0.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer4.0.downsample.0: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "base_model.layer4.1.conv1: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.layer4.1.conv2: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "base_model.fc: Linear(in_features=512, out_features=5, bias=True)\n",
            "Output Shape: [5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCjGxambopvv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}